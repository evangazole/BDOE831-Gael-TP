"""
Script PySpark pour entra√Æner un mod√®le de d√©tection d'intrusion.

Ce script :
1. Lit les donn√©es transform√©es (Parquet)
2. Pr√©pare les features (encodage, normalisation)
3. Entra√Æne un mod√®le de R√©gression Logistique (classification binaire)
4. √âvalue le mod√®le (Matrice de confusion, Accuracy, Pr√©cision, Recall)
5. Sauvegarde le mod√®le entra√Æn√© dans MinIO
"""

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml import Pipeline
from pyspark.sql.functions import col

# Cr√©er la session Spark
spark = SparkSession.builder \
    .appName("Train Intrusion Detection Model") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.secret.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
    .getOrCreate()

print("=" * 80)
print("Entra√Ænement du Mod√®le de D√©tection d'Intrusion")
print("=" * 80)

# 1. Lecture des donn√©es transform√©es
print("\nüìñ Lecture des donn√©es transform√©es...")
df = spark.read.parquet("s3a://data-lake/processed/network_logs_cleaned.parquet")
print(f"‚úì Donn√©es charg√©es : {df.count()} lignes")

# 2. Affichage du sch√©ma
print("\nSch√©ma des donn√©es :")
df.printSchema()

# 3. Identification de la colonne label
# Note: Adapter selon le nom r√©el de la colonne dans votre dataset
# Exemples courants : 'label', 'Label', 'class', 'attack_type', 'is_intrusion'
label_col = None
for possible_label in ['label', 'Label', 'class', 'attack_type', 'is_intrusion', 'target']:
    if possible_label in df.columns:
        label_col = possible_label
        break

if label_col is None:
    print("\n‚ö†Ô∏è  ATTENTION : Aucune colonne label trouv√©e dans le dataset.")
    print("   Colonnes disponibles :", df.columns)
    print("   Pour un apprentissage supervis√©, vous devez avoir une colonne label.")
    print("   Cr√©ation d'une colonne label factice pour d√©monstration...")
    # Cr√©er une colonne label factice (√† remplacer par la vraie colonne)
    df = df.withColumn("label", (col(df.columns[0]) % 2).cast("double"))
    label_col = "label"

print(f"\n‚úì Colonne label identifi√©e : '{label_col}'")

# 4. S√©lection des features num√©riques
numeric_features = [field.name for field in df.schema.fields 
                    if str(field.dataType) in ['IntegerType', 'DoubleType', 'LongType', 'FloatType']
                    and field.name != label_col]

print(f"\nüìä Features num√©riques s√©lectionn√©es ({len(numeric_features)}) :")
print(numeric_features[:10], "..." if len(numeric_features) > 10 else "")

# 5. Pr√©paration des features
print("\nüîß Pr√©paration des features...")

# Assembler les features en un vecteur
assembler = VectorAssembler(
    inputCols=numeric_features,
    outputCol="features_raw",
    handleInvalid="skip"
)

# Normalisation des features
scaler = StandardScaler(
    inputCol="features_raw",
    outputCol="features",
    withStd=True,
    withMean=True
)

# 6. Cr√©ation du mod√®le de R√©gression Logistique
print("\nü§ñ Cr√©ation du mod√®le de R√©gression Logistique...")
lr = LogisticRegression(
    featuresCol="features",
    labelCol=label_col,
    maxIter=100,
    regParam=0.01,
    elasticNetParam=0.8
)

# 7. Pipeline ML
pipeline = Pipeline(stages=[assembler, scaler, lr])

# 8. Split train/test
print("\nüìä S√©paration des donn√©es (80% train, 20% test)...")
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
print(f"‚úì Train : {train_df.count()} lignes")
print(f"‚úì Test : {test_df.count()} lignes")

# 9. Entra√Ænement du mod√®le
print("\nüöÄ Entra√Ænement du mod√®le...")
model = pipeline.fit(train_df)
print("‚úì Mod√®le entra√Æn√© avec succ√®s")

# 10. Pr√©dictions sur le test set
print("\nüîÆ Pr√©dictions sur le test set...")
predictions = model.transform(test_df)

# 11. √âvaluation du mod√®le
print("\nüìà √âvaluation du mod√®le :")
print("-" * 80)

# Accuracy
evaluator_accuracy = MulticlassClassificationEvaluator(
    labelCol=label_col,
    predictionCol="prediction",
    metricName="accuracy"
)
accuracy = evaluator_accuracy.evaluate(predictions)
print(f"‚úì Accuracy : {accuracy:.4f}")

# Precision
evaluator_precision = MulticlassClassificationEvaluator(
    labelCol=label_col,
    predictionCol="prediction",
    metricName="weightedPrecision"
)
precision = evaluator_precision.evaluate(predictions)
print(f"‚úì Precision : {precision:.4f}")

# Recall
evaluator_recall = MulticlassClassificationEvaluator(
    labelCol=label_col,
    predictionCol="prediction",
    metricName="weightedRecall"
)
recall = evaluator_recall.evaluate(predictions)
print(f"‚úì Recall : {recall:.4f}")

# F1-Score
evaluator_f1 = MulticlassClassificationEvaluator(
    labelCol=label_col,
    predictionCol="prediction",
    metricName="f1"
)
f1 = evaluator_f1.evaluate(predictions)
print(f"‚úì F1-Score : {f1:.4f}")

# AUC-ROC
evaluator_auc = BinaryClassificationEvaluator(
    labelCol=label_col,
    rawPredictionCol="rawPrediction",
    metricName="areaUnderROC"
)
auc = evaluator_auc.evaluate(predictions)
print(f"‚úì AUC-ROC : {auc:.4f}")

# 12. Affichage de quelques pr√©dictions
print("\nüîç Exemples de pr√©dictions :")
predictions.select(label_col, "prediction", "probability").show(10, truncate=False)

# 12.5. Sauvegarde des pr√©dictions pour PowerBI
print("\nüíæ Sauvegarde des pr√©dictions pour visualisation...")
predictions_path = "s3a://data-lake/processed/classified_logs.parquet"
predictions.write.mode("overwrite").parquet(predictions_path)
print(f"‚úì Pr√©dictions sauvegard√©es : {predictions_path}")

# 13. Sauvegarde du mod√®le
print("\nüíæ Sauvegarde du mod√®le...")
model_path = "s3a://data-lake/models/intrusion_detection_model"
model.write().overwrite().save(model_path)
print(f"‚úì Mod√®le sauvegard√© : {model_path}")

# 14. R√©sum√© final
print("\n" + "=" * 80)
print("‚úÖ Entra√Ænement termin√© avec succ√®s")
print("=" * 80)
print(f"\nüìä R√©sum√© des performances :")
print(f"   - Accuracy  : {accuracy:.4f}")
print(f"   - Precision : {precision:.4f}")
print(f"   - Recall    : {recall:.4f}")
print(f"   - F1-Score  : {f1:.4f}")
print(f"   - AUC-ROC   : {auc:.4f}")
print("\n" + "=" * 80)

spark.stop()
